{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QauSci7RYOqk"
      },
      "source": [
        "# PySpark\n",
        "\n",
        "To install and run PySpark on Jupyter Notebook, see: https://technofob.com/2018/12/26/how-to-run-pyspark-2-4-0-in-jupyter-notebook-on-mac/\n",
        "\n",
        "Main reference for this tutorial: https://spark.apache.org/docs/latest/rdd-programming-guide.html and https://spark.apache.org/examples.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcT9mJFbZmku",
        "outputId": "82fb9cdb-991e-486a-9a5b-89687e65d5f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=dc4394b1b2869e98344e85a239e4da3f6c2000f04031da1087a45a11670bd6f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u392-ga-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u392-ga-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nClcjYYyYOql"
      },
      "outputs": [],
      "source": [
        "# We start by getting the spark context\n",
        "from pyspark import SparkContext, SparkConf\n",
        "sc = SparkContext.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBG6ZJhFYOqn"
      },
      "source": [
        "## Resilient Distributed Dataset (RDD)\n",
        "\n",
        "An RDD can be created from parallelizing an existing collection in the driver program, or referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U0IADQKaYOqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fbbe43b-ce56-4e77-fd7a-b18fb243ff7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:289"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
        "distData = sc.parallelize(data)\n",
        "\n",
        "distData"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVemnYKJYOqn"
      },
      "source": [
        "Let us look at how the parallelization worked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "we97t5PoYOqn"
      },
      "outputs": [],
      "source": [
        "distData.saveAsTextFile(\"/Users/Sharanya/spark-playground/data1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk3B1LrOYOqn"
      },
      "source": [
        "Spark chooses a suitable number of partitions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxPD9cy0YOqo"
      },
      "source": [
        "### Specifying number of partitions manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CEUKQja5YOqo"
      },
      "outputs": [],
      "source": [
        "distData2 = sc.parallelize(data,4) # 4 partitions\n",
        "distData2.saveAsTextFile(\"/Users/Sharanya/spark-playground/data2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C17l1vGwYOqo"
      },
      "source": [
        "## Lambda: anonymous function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B5tZ6nCBYOqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e4ba59-d95d-41d3-b5dc-854591a00b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "# This is the usual way to define a function\n",
        "def add1(a,b):\n",
        "    return a+b\n",
        "\n",
        "print(add1(2,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n0oP2a_SYOqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7748426-65b0-4ad2-e7cb-53eb68728312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "# This is the way to define an anonymous function\n",
        "add2 = lambda a, b : a + b\n",
        "\n",
        "print(add2(2,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMd8zXOCYOqp"
      },
      "source": [
        "## Map: apply some function to all elements of the list\n",
        "\n",
        "Map takes a function and a list as arguments and applies the functions to all the elements of the list. For example, the following would map a list of numbers to the list of it's squares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "27iuiPZGYOqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd9295f-2078-4dd7-bc3a-9ec0999ead12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
          ]
        }
      ],
      "source": [
        "# Recall that we already had a list of integers\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gT-0GDHCYOqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ea1915-e4fd-47e9-f0f2-f2b6d0f474ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400]\n"
          ]
        }
      ],
      "source": [
        "def sq(a):\n",
        "    return a*a\n",
        "\n",
        "data_sq = list(map(sq, data))\n",
        "print(data_sq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZBZcEELYOqp"
      },
      "source": [
        "### Using lambda with map\n",
        "\n",
        "But it is more convenient to use a lambda function for this instead of defining a new function sq."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ING7H0I7YOqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af02566e-5235-4fa2-f1f0-d82def26de5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400]\n"
          ]
        }
      ],
      "source": [
        "data_sq = list(map(lambda a : a*a, data))\n",
        "print(data_sq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yQpRmR4YOqp"
      },
      "source": [
        "## Reduce: apply a function repetitively on pairs of a list\n",
        "\n",
        "This works best when at each step we reduce the pair of elements to a single number, so that overall the list is reduced to a single number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9Sv0I5ElYOqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbcbd89b-bf93-41d1-b12f-bdfd866ba59a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210\n"
          ]
        }
      ],
      "source": [
        "from functools import reduce\n",
        "data_sum = reduce(lambda a,b : a + b, data)\n",
        "print(data_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "691n297YYOqq"
      },
      "source": [
        "## Spark RDD basic operations\n",
        "\n",
        "Once an RDD is created, spark offers many basic operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lbbz-l8GYOqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1931f729-5bc1-44d7-dd53-a04dda919df0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Collect returns all elements of the dataset as an array.\n",
        "# Only to be used for an RDD that is small enough\n",
        "distData.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BhcIKDe5YOqq"
      },
      "outputs": [],
      "source": [
        "# Example of filter\n",
        "def smallNumber(x):\n",
        "    return x < 10\n",
        "\n",
        "filtered = distData.filter(smallNumber)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Dpxj6S-TYOqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aec805a-cbb1-4dd4-aeb4-90984c8359c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "filtered.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Q2yGi6dKYOqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdf4755-9915-4432-9996-6a0be826c9d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# In the real practical case, collect is not advisable at all.\n",
        "# Use first() or takeSample\n",
        "distData.first()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_G-ecB_SYOqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da188ec-3d98-405b-8440-a898d809c791"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[17, 1, 11, 3, 9, 3, 2, 14, 14, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Take a sample of n elements, with or without replacement\n",
        "distData.takeSample(True, 10)\n",
        "#distData.takeSample(False, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Yq1u9S7UYOqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6492a5-d4b4-4156-ec74-de514ef8cbd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "distData.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "senrjnUZYOqq"
      },
      "source": [
        "## RDD from external fies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1KOCPMtyYOqq"
      },
      "outputs": [],
      "source": [
        "trump = sc.textFile(\"/Users/Sharanya/spark-playground/Trump.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oTgZL0VQYOqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d33c36b-a524-4f83-a74a-c5c024fe1e52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['No, I have no intention of changing my mind.',\n",
              " '',\n",
              " '',\n",
              " 'To me, it was instructional.',\n",
              " 'They put Hillary’s numbers. And I’m winning by a lot and they said, \"Donald Trump is winning. You know, let’s go to a new subject, okay?\"',\n",
              " '',\n",
              " '',\n",
              " 'Here’s the problem. From the standpoint of bookkeeping, from the standpoint of bureaucracy, you’re talking about millions and millions of returns. You’re talking about building the IRS even bigger and it’s a monster. And I could cut it down way down. And the money that you’re talking about is far less than the administrative costs.',\n",
              " '',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "trump.takeSample(False,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LaGzSW6YOqr"
      },
      "source": [
        "# The word count problem in MapReduce (with Spark)\n",
        "\n",
        "Now we are ready to write the code for the wordcount problem in a MapReduce fashion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wD2f1ijwYOqr"
      },
      "outputs": [],
      "source": [
        "# Create the RDD\n",
        "# Already done above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqMHJgQ0YOqr"
      },
      "source": [
        "At this point, it has performed no task, has not even read the data (lazy). Spark will perform the task only if we call for some output to be sent to the driver."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFxW4c8mYOqr"
      },
      "source": [
        "Let us examine (for understanding) what's in there. It should be a list of strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "x29xIFFyYOqr"
      },
      "outputs": [],
      "source": [
        "#lines.takeSample(False,8)\n",
        "#lines.collect()\n",
        "\n",
        "# lines\n",
        "#lines.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1CZu6oJ5YOqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e1b91ed-ed30-4e94-c37e-0871c4548ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Debapriyo', 'Majumdar']\n"
          ]
        }
      ],
      "source": [
        "# Recall what split does\n",
        "text = \"Debapriyo Majumdar\"\n",
        "print(text.split(\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sfOQMskYOqr"
      },
      "source": [
        "Now let us generate the key value pairs. For each word $w$, send $w$ to $(w,1)$. But for that we need to split the strings into words as well. Let us try map for that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4Mh9RevbYOqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8691b1bd-5453-4c4c-9805-a9101135ec8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['As',\n",
              "  'far',\n",
              "  'as',\n",
              "  'Jeb',\n",
              "  'is',\n",
              "  'concerned,',\n",
              "  'I',\n",
              "  'watched',\n",
              "  'him',\n",
              "  'this',\n",
              "  'morning',\n",
              "  'on',\n",
              "  'television',\n",
              "  'and',\n",
              "  'it’s',\n",
              "  'a',\n",
              "  'little',\n",
              "  'bit',\n",
              "  'sad.'],\n",
              " ['And',\n",
              "  'this',\n",
              "  'really',\n",
              "  'pertains',\n",
              "  'to',\n",
              "  'allowing',\n",
              "  'people',\n",
              "  'into',\n",
              "  'our',\n",
              "  'country',\n",
              "  'that',\n",
              "  'we',\n",
              "  'know',\n",
              "  'are',\n",
              "  'going',\n",
              "  '–',\n",
              "  'we’re',\n",
              "  'going',\n",
              "  'to',\n",
              "  'have',\n",
              "  'problems.',\n",
              "  'We’re',\n",
              "  'going',\n",
              "  'to',\n",
              "  'have',\n",
              "  'huge',\n",
              "  'problems.',\n",
              "  'Allowing',\n",
              "  'people',\n",
              "  'in',\n",
              "  'from',\n",
              "  'areas',\n",
              "  'of',\n",
              "  'the',\n",
              "  'world',\n",
              "  'we',\n",
              "  'don’t',\n",
              "  'know',\n",
              "  'where',\n",
              "  'they',\n",
              "  'come',\n",
              "  'from.',\n",
              "  'We',\n",
              "  'don’t',\n",
              "  'know',\n",
              "  'where',\n",
              "  'their',\n",
              "  'documents',\n",
              "  'are.',\n",
              "  'They',\n",
              "  'say',\n",
              "  'they',\n",
              "  'don’t',\n",
              "  'have',\n",
              "  'documents.',\n",
              "  'They',\n",
              "  'have',\n",
              "  'no',\n",
              "  'papers.',\n",
              "  'No',\n",
              "  'nothing.',\n",
              "  'We',\n",
              "  'let',\n",
              "  'them',\n",
              "  'in.',\n",
              "  'How',\n",
              "  'stupid',\n",
              "  'can',\n",
              "  'we',\n",
              "  'be?'],\n",
              " [''],\n",
              " ['When',\n",
              "  'they',\n",
              "  'start',\n",
              "  'dancing',\n",
              "  'about',\n",
              "  'a',\n",
              "  'deal',\n",
              "  'that',\n",
              "  'I’m',\n",
              "  'making,',\n",
              "  'when',\n",
              "  'they',\n",
              "  'start',\n",
              "  'burning',\n",
              "  'the',\n",
              "  'American',\n",
              "  'flag,',\n",
              "  'I’m',\n",
              "  'out',\n",
              "  'of',\n",
              "  'there.',\n",
              "  'Bye',\n",
              "  'bye.',\n",
              "  'Good',\n",
              "  'luck.'],\n",
              " ['These',\n",
              "  'are',\n",
              "  'the',\n",
              "  'people',\n",
              "  '–',\n",
              "  'you',\n",
              "  'know,',\n",
              "  'if',\n",
              "  'these',\n",
              "  'people',\n",
              "  'about',\n",
              "  'Trump',\n",
              "  '–',\n",
              "  'they',\n",
              "  'call',\n",
              "  'it',\n",
              "  'like',\n",
              "  '\"No',\n",
              "  'Trump\".',\n",
              "  'What',\n",
              "  'do',\n",
              "  'they',\n",
              "  'call',\n",
              "  'that',\n",
              "  'thing?',\n",
              "  'They',\n",
              "  'call',\n",
              "  'it',\n",
              "  '\"Never',\n",
              "  'Trump\".',\n",
              "  'Oh,',\n",
              "  'you',\n",
              "  'need',\n",
              "  'Trump',\n",
              "  'so',\n",
              "  'badly',\n",
              "  'though.'],\n",
              " ['Many',\n",
              "  'of',\n",
              "  'the',\n",
              "  'hospitals',\n",
              "  'are',\n",
              "  'dying',\n",
              "  'for',\n",
              "  'business.',\n",
              "  'You',\n",
              "  'know',\n",
              "  'that',\n",
              "  'they’re',\n",
              "  'dying.',\n",
              "  'Some',\n",
              "  'of',\n",
              "  'these',\n",
              "  'hospitals',\n",
              "  'are',\n",
              "  'dying.',\n",
              "  'They’re',\n",
              "  'going',\n",
              "  'to',\n",
              "  'get',\n",
              "  'immediate',\n",
              "  'treatment,',\n",
              "  'immediate',\n",
              "  'service,',\n",
              "  'we’re',\n",
              "  'going',\n",
              "  'to',\n",
              "  'pay',\n",
              "  'the',\n",
              "  'bills,',\n",
              "  'and',\n",
              "  'we’re',\n",
              "  'going',\n",
              "  'to',\n",
              "  'save',\n",
              "  'a',\n",
              "  'fortune,',\n",
              "  'and',\n",
              "  'they’re',\n",
              "  'going',\n",
              "  'to',\n",
              "  'get',\n",
              "  'great',\n",
              "  'service.'],\n",
              " [''],\n",
              " ['Which',\n",
              "  'they',\n",
              "  'are.',\n",
              "  'Or',\n",
              "  'there’s',\n",
              "  'something',\n",
              "  'going',\n",
              "  'on.',\n",
              "  'Because',\n",
              "  'it’s',\n",
              "  '—',\n",
              "  'it’s',\n",
              "  'inconceivable.',\n",
              "  'You',\n",
              "  'know,',\n",
              "  'do',\n",
              "  'you',\n",
              "  'ever',\n",
              "  'see',\n",
              "  'where',\n",
              "  'some',\n",
              "  'things',\n",
              "  'are',\n",
              "  'so',\n",
              "  'bad',\n",
              "  'that',\n",
              "  'it',\n",
              "  'can’t',\n",
              "  'be',\n",
              "  '—',\n",
              "  'that',\n",
              "  'nobody',\n",
              "  'can',\n",
              "  'do',\n",
              "  'what',\n",
              "  'they',\n",
              "  'did,',\n",
              "  'right?',\n",
              "  'Nobody.'],\n",
              " [''],\n",
              " ['You’ll',\n",
              "  'see',\n",
              "  'it',\n",
              "  'later.',\n",
              "  'Yeah.',\n",
              "  'They',\n",
              "  'don’t',\n",
              "  'want',\n",
              "  'to',\n",
              "  'hear',\n",
              "  'it.']]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "words = trump.map(lambda line : line.split(\" \"))\n",
        "\n",
        "words.takeSample(False,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTTekTogYOqs"
      },
      "source": [
        "Unfortunately it has created a list of lists of words. We would like a list of words. So, we use flatMap instead of map. It flattens it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "caF4BbTtYOqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5043cbd0-38c4-4b77-e879-4fea2153e848"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "171898"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "words = trump.flatMap(lambda line : line.split(\" \"))\n",
        "\n",
        "words.takeSample(False,30)\n",
        "words.count()\n",
        "\n",
        "#words\n",
        "#words.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwbUdK8sYOqv"
      },
      "source": [
        "Now that we have a list of words, we can use the map $w \\mapsto (w,1)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4iCTfIMyYOqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d657957-d8bf-41e4-a1e6-6f5ce6fc732e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('going', 1),\n",
              " ('what', 1),\n",
              " ('ENEMIES', 1),\n",
              " ('he', 1),\n",
              " ('be', 1),\n",
              " ('them', 1),\n",
              " ('building', 1),\n",
              " ('the', 1),\n",
              " ('going', 1),\n",
              " ('spin', 1),\n",
              " ('it.', 1),\n",
              " ('We’re', 1),\n",
              " ('us', 1),\n",
              " ('a', 1),\n",
              " ('the', 1),\n",
              " ('you.', 1),\n",
              " ('not', 1),\n",
              " ('I', 1),\n",
              " ('I', 1),\n",
              " ('landscape', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "keyVal = words.map(lambda w : (w,1))\n",
        "keyVal.takeSample(False,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QQw3hc0YOqv"
      },
      "source": [
        "Now we use the function reduceByKey in Spark. It groups by key and applies reduce to the list of values for each key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8fRoiR-NYOqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6967c218-30f3-4936-ca8f-5f7a41485369"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('she’d', 2),\n",
              " ('Bibi.', 4),\n",
              " ('wages.', 2),\n",
              " ('contribute', 1),\n",
              " ('Phony.', 1),\n",
              " ('excavator.', 1),\n",
              " ('Cole.', 1),\n",
              " ('PROBLEM', 3),\n",
              " ('growth,', 2),\n",
              " ('reading,', 1),\n",
              " ('Rich', 1),\n",
              " ('…Do', 1),\n",
              " ('successful', 28),\n",
              " ('similar', 2),\n",
              " ('Ole', 2),\n",
              " ('FIGHTING.', 1),\n",
              " ('Pfizer?', 1),\n",
              " ('Street.', 1),\n",
              " ('range', 1),\n",
              " ('independents,', 1),\n",
              " ('chances.', 1),\n",
              " ('night', 23),\n",
              " ('spewing', 2),\n",
              " ('musicians', 1),\n",
              " ('Seriously.', 1),\n",
              " ('Third', 3),\n",
              " ('ministers.', 2),\n",
              " ('Authority', 1),\n",
              " ('candidacy?\"', 1),\n",
              " ('Trump?', 4),\n",
              " ('incredible,', 3),\n",
              " ('something', 138),\n",
              " ('claiming', 1),\n",
              " ('possible,', 1),\n",
              " ('competitive', 1),\n",
              " ('whom', 8),\n",
              " ('taken,', 1),\n",
              " ('Stop', 1),\n",
              " ('sake', 1),\n",
              " ('accomplished', 3),\n",
              " ('SON.', 1),\n",
              " ('Gov.', 4),\n",
              " ('this.', 84),\n",
              " ('MESSENGER,', 1),\n",
              " ('originally', 2),\n",
              " ('bill.', 1),\n",
              " ('adds', 1),\n",
              " ('insulted,', 1),\n",
              " ('CNBC.', 1),\n",
              " ('really,', 11),\n",
              " ('Independents', 1),\n",
              " ('Nah,', 1),\n",
              " ('COACHES,', 1),\n",
              " ('end,', 11),\n",
              " ('points.\"', 1),\n",
              " ('racial', 3),\n",
              " ('America\"', 2),\n",
              " ('wants.', 2),\n",
              " ('\"Your', 1),\n",
              " ('marginalizing', 1),\n",
              " ('estate,', 1),\n",
              " ('case…like', 1),\n",
              " ('stopping', 4),\n",
              " ('1997', 1),\n",
              " ('understand…He’s', 1),\n",
              " ('Fox.', 2),\n",
              " ('engaged', 1),\n",
              " ('nationwide.', 2),\n",
              " ('reference.', 1),\n",
              " (\"I'm\", 35),\n",
              " ('country...You', 1),\n",
              " ('brought', 32),\n",
              " ('AMATEURS.', 1),\n",
              " ('RATHER', 3),\n",
              " ('stopping.', 1),\n",
              " ('employees', 3),\n",
              " ('entering', 1),\n",
              " ('zone.', 2),\n",
              " ('Man,', 1),\n",
              " ('programs,', 1),\n",
              " ('better?', 4),\n",
              " ('veteran,', 2),\n",
              " ('“The', 1),\n",
              " (\"You'll\", 1),\n",
              " ('genius', 3),\n",
              " ('LOS', 1),\n",
              " ('converting', 1),\n",
              " ('delays,', 2),\n",
              " ('runs', 3),\n",
              " ('double', 8),\n",
              " ('player', 2),\n",
              " ('\"Skip', 1),\n",
              " ('ANYMORE.', 2),\n",
              " ('Bibi', 1),\n",
              " ('cocaine', 1),\n",
              " ('’04.', 1),\n",
              " ('insulting?\"', 1),\n",
              " ('WIFE', 1),\n",
              " ('with.', 7),\n",
              " ('working', 33)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "counts = keyVal.reduceByKey(lambda m, n: m + n)\n",
        "counts.takeSample(False,100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsm3tgEbYOqw"
      },
      "source": [
        "We could as well write this whole thing in a more crips code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5cZjNhSAYOqw"
      },
      "outputs": [],
      "source": [
        "# def processText(text):\n",
        "#    return text.split(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1Rzs29CzYOqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d6fc9a4-1e1f-4e24-a2ef-1d5b882464c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('shows.', 3),\n",
              " ('bound,', 1),\n",
              " ('likewise,', 3),\n",
              " ('Gov.', 4),\n",
              " ('firm', 1),\n",
              " ('ACHIEVEMENT', 1),\n",
              " ('thing…I', 1),\n",
              " ('premiums', 3),\n",
              " (\"weren't\", 1),\n",
              " ('statisticians.', 1),\n",
              " ('unbelievably', 9),\n",
              " ('essentially', 8),\n",
              " ('Icahn.\"', 1),\n",
              " ('Won’t', 1),\n",
              " ('tens', 15),\n",
              " ('federal', 3),\n",
              " ('9%,', 1),\n",
              " ('laws.', 4),\n",
              " ('REGULATIONS', 2),\n",
              " ('\"What?\"', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "lines = sc.textFile(\"/Users/Sharanya/spark-playground/Trump.txt\")\n",
        "counts = lines.flatMap(lambda line: line.split(\" \")) \\\n",
        "             .map(lambda word: (word , 1)) \\\n",
        "             .reduceByKey(lambda m,n: m + n)\n",
        "\n",
        "# We can save the result if we want\n",
        "counts.saveAsTextFile(\"/Users/Sharanya/spark-playground/Trump_wordcount\")\n",
        "counts.takeSample(True,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmqK24PNYOqw"
      },
      "source": [
        "# A Monte-Carlo simulation\n",
        "\n",
        "Estimate the value of Pi, the area of a unit circle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DTX0FeE3YOqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73fe165c-a490-4e30-84f2-daabd890af27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pi is roughly 3.142102\n",
            "CPU times: user 38.4 ms, sys: 7.76 ms, total: 46.2 ms\n",
            "Wall time: 9.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def inside(p):\n",
        "    x, y = np.random.random(), np.random.random()\n",
        "    return x*x + y*y < 1\n",
        "\n",
        "NUM_SAMPLES = 10000 * 1000\n",
        "count = sc.parallelize(range(0, NUM_SAMPLES),4)\\\n",
        "          .filter(inside).count()\n",
        "#print(count)\n",
        "\n",
        "print(\"Pi is roughly %f\" % (4.0 * count / NUM_SAMPLES))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}