{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DBLP Co-authorship Data Analysis\n",
        "## Submitted By : Sharanya Dasgupta\n",
        "## Roll No.: CS2320"
      ],
      "metadata": {
        "id": "9o-NbUXKgAc3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnjkTgXVNEOv"
      },
      "source": [
        "\n",
        "\n",
        "This is the Colab version of the notebook.\n",
        "\n",
        "In this assignment, you are given an undirected graph (<a href=\"https://snap.stanford.edu/data/com-DBLP.html\">DBLP co-authorship</a>) in the edge list format. Each author is represented by an anonymous integer ID. Each line of the file contains the ID of two authors who have co-authored at least one paper together, separated by a TAB.\n",
        "\n",
        "The original file has some extra lines in the beginning but those have been removed in the file given to you.\n",
        "\n",
        "If you are using your own system, download the data here: <a href=\"https://drive.google.com/file/d/1B-cimWJmdEJio07kBBBH1RpyAhhG-euQ/view?usp=sharing\">Download the data</a>.\n",
        "\n",
        "If you are running it on colab, then the data can be imported by the cells given below, no need to download a local copy.\n",
        "\n",
        "You may assume that each edge is represented in the file only once, but the order of the nodes are not known. In other words, if <tt>(a,b)</tt> is an edge in the graph, then the file contains either a line '<tt>a TAB b</tt>' or '<tt>b TAB a</tt>', but not both and there is no duplicate line.\n",
        "\n",
        "For each of the tasks below, you are instructed to implement a function. Use appropriate map and reduce (or other spark / python functions) as you require to implement those. If you need to define any other function (e.g., a separate function for map or reduce), feel free to define those in the same cell above the desired function."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting PySpark to work with Colab\n",
        "\n",
        "Execute the cells below to make pyspark to work with colab."
      ],
      "metadata": {
        "id": "ImzhRxbaOFbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "4UmwNmM9OD2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b43c33-ce49-415a-9903-2c17746d1b4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=ec3239f0588cf01bd7aaa3600f08e47baa13a561ff8138ee49954efd5dab7e90\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u392-ga-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u392-ga-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Google Drive to work with Colab"
      ],
      "metadata": {
        "id": "JpFmhhwSO-Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id='1B-cimWJmdEJio07kBBBH1RpyAhhG-euQ'\n",
        "filename = 'com-dblp.ungraph.txt'\n",
        "\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile(filename)"
      ],
      "metadata": {
        "id": "BevqwCIeO6f7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9vIMNBQsNEO0"
      },
      "outputs": [],
      "source": [
        "# We start by getting the spark context\n",
        "from pyspark import SparkContext, SparkConf\n",
        "sc = SparkContext.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3dyU6EMNEO3"
      },
      "source": [
        "## Create an RDD from the input file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kFGhcOipNEO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed51a9d-b078-40f3-ce65-d6b6781184ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['46395\\t86575',\n",
              " '41654\\t107818',\n",
              " '231445\\t322853',\n",
              " '76909\\t83620',\n",
              " '246430\\t380199',\n",
              " '21642\\t24286',\n",
              " '111003\\t131731',\n",
              " '32951\\t234250',\n",
              " '407896\\t407897',\n",
              " '133771\\t345198']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Use the appropriate file path for file downloaded in your system\n",
        "# edgeList = sc.textFile(\"/Users/debapriyo/spark-playground/com-dblp.ungraph.txt\")\n",
        "\n",
        "# Use this line for running on Colab\n",
        "edgeList = sc.textFile(filename)\n",
        "\n",
        "# See some sample lines\n",
        "edgeList.takeSample(False,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfOhEOd0NEO4"
      },
      "source": [
        "If you count the number of edges, you should get 1049866."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V0I1M1xvNEO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69652a16-75bb-4102-fe09-384042baf7e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1049866"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Use the built in Spark function to count the number of lines (elements in the RDD) (ungraded)\n",
        "edgeList.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHEZP0HHNEO6"
      },
      "source": [
        "## Task 1: Compute the number of co-authors (degree) for each author (3 marks)\n",
        "\n",
        "Find the degree of each node. Be mindful of the fact that the graph is undirected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JwqPxQWwNEO6"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Input: an RDD in the edgelist format as above\n",
        "    Returns: an RDD with each element being a pair (node_ID, degree)\n",
        "\"\"\"\n",
        "def degree(edgeList):\n",
        "\n",
        "  # Flattened list of author_ids\n",
        "  Author_ids = edgeList.flatMap(lambda line : line.split(\"\\t\"))\n",
        "\n",
        "  # Each Presence of an author_id contributes 1 towards it's total degree (as the graph is undirected)\n",
        "  degree = Author_ids.map(lambda a : (a,1))\n",
        "\n",
        "  # Summing up the total degree of each author_id by reduceByKey operation\n",
        "  Author_degrees = degree.reduceByKey(lambda m, n: m + n)\n",
        "\n",
        "  return Author_degrees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n3wDJsUaNEO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b25f1e9-10d0-4634-bb77-2fc8ee08126e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('299341', 1),\n",
              " ('188121', 4),\n",
              " ('201535', 3),\n",
              " ('385766', 2),\n",
              " ('286551', 2),\n",
              " ('327932', 2),\n",
              " ('283069', 4),\n",
              " ('238237', 2),\n",
              " ('364624', 3),\n",
              " ('262966', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "degrees = degree(edgeList)\n",
        "degrees.takeSample(False,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC68RUS9NEO7"
      },
      "source": [
        "A sample of the RDD returned by the <tt>degree</tt> function should have the following format:\n",
        "\n",
        "````{verbatim}\n",
        "[('86281', 15),\n",
        " ('364476', 8),\n",
        " ('277755', 2),\n",
        " ('372715', 2),\n",
        " ('60523', 3),\n",
        " ('370437', 3),\n",
        " ('191955', 11),\n",
        " ('286360', 113),\n",
        " ('264995', 10),\n",
        " ('308008', 2)]\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpzYfsq2NEO8"
      },
      "source": [
        "## Task 2: Convert to adjacency-list format (3 marks)\n",
        "\n",
        "Convert the data from edge-list format to the adjacency-list format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PMa-t16lNEO8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Input: an RDD in the edgelist format as above\n",
        "    Returns: an RDD with each element being a pair (node_ID, list of adjacent node IDs)\n",
        "             i.e., (string,list)\n",
        "\"\"\"\n",
        "# Defining functions for creating adjacency-list while combineByKey\n",
        "\n",
        "def adj_list(a,b): # Converting two lists into single sorted list\n",
        "    a.extend(b)\n",
        "    a.sort(key=int)\n",
        "    return a\n",
        "\n",
        "def toAdjList(edgeList):\n",
        "\n",
        "  # Creating list of lists of Coauthors\n",
        "  edges = edgeList.map(lambda line : line.split(\"\\t\"))\n",
        "\n",
        "  # Each Edge contributes towards the adjacency-lists of both end nodes\n",
        "  edge1 = edges.map(lambda w : (w[0],[w[1]]))\n",
        "  edge2 = edges.map(lambda w : (w[1],[w[0]]))\n",
        "  effective_edges=edge1.union(edge2)\n",
        "\n",
        "  # Creating adjacency-list for each author_id by combineByKey operation and defined functions\n",
        "  adjacency_list=effective_edges.reduceByKey(adj_list)\n",
        "\n",
        "  return adjacency_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YU4mtA0DNEO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66a17ab-5f36-4a63-ec50-ab5104c22eb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('206883', ['45992', '109764']),\n",
              " ('255676', ['6535', '9935', '109620', '233521'])]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "adjList = toAdjList(edgeList)\n",
        "adjList.takeSample(False,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-6le3ebNEO9"
      },
      "source": [
        "A sample of the <tt>adjList</tt> RDD should be of the following format:\n",
        "````{verbatim}\n",
        "[('229379',\n",
        "  ['16758',\n",
        "   '20208',\n",
        "   '84673',\n",
        "   '86302',\n",
        "   '201707',\n",
        "   '208085',\n",
        "   '229377',\n",
        "   '229378',\n",
        "   '270355',\n",
        "   '284357',\n",
        "   '299813',\n",
        "   '344507']),\n",
        " ('92555', ['43489', '58094', '92554'])]\n",
        "````\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMLR71UvNEO-"
      },
      "source": [
        "## Task 3: Compute the number of mutual co-authors (4 marks)\n",
        "\n",
        "From either the edge-list representation or the adjacency-list representation, compute the number of mutual co-authors for each pair of authors (only for pairs of authors for whom there is any co-author at all)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gSlsZhP8NEO-"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Input: an RDD in the edgelist or adjacency list format as above\n",
        "    Returns: an RDD with each element being a pair\n",
        "             (pair of author IDs, number of mutual co-authors for those authors)\n",
        "             i.e., (string,integer)\n",
        "\"\"\"\n",
        "# For each member in adjacency-list (Y1, Y2, … , Yn) of an author X\n",
        "# For each pair (Y1, Y2), emitting the key value pair (Y1-Y2,1)\n",
        "# Since, each such pair contributes one towards their no. of mutual co-authors\n",
        "\n",
        "def MutualCoAuthor(w):\n",
        "  ls=[]\n",
        "  res = w[1]\n",
        "  # Iterating through adjacency-list to emit key value pair (Y1-Y2,1)\n",
        "  for i in range(0,len(res),1):\n",
        "    for j in range(i+1,len(res),1):\n",
        "      ls.append((str(res[i])+'-'+str(res[j]),1))\n",
        "  return ls\n",
        "\n",
        "def numMutualCoAuthors(data):\n",
        "\n",
        "  # Flattened list of key value pairs (Y1-Y2,1)\n",
        "  CoAuthor=data.flatMap(MutualCoAuthor)\n",
        "\n",
        "  # Summing up the total no. of mutual co-authors of each pair of author_id by reduceByKey operation\n",
        "  MutualCoAuthors=CoAuthor.reduceByKey(lambda m, n: m + n)\n",
        "\n",
        "  return MutualCoAuthors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GANl0yScNEO_"
      },
      "source": [
        "Now, execute the process. Even with good programming, it may take a few minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZEgi4SfKNEO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f26a7e-d658-435b-b12c-19d8b7ce0a87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('101895-322836', 1),\n",
              " ('1111-12605', 1),\n",
              " ('58316-101799', 1),\n",
              " ('10275-40145', 1),\n",
              " ('70047-186671', 1),\n",
              " ('198239-380100', 1),\n",
              " ('195464-267276', 1),\n",
              " ('121221-324055', 1),\n",
              " ('56723-73918', 1),\n",
              " ('116176-155494', 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# use one of the following lines depending on your function\n",
        "# Using adjacency list\n",
        "data = adjList\n",
        "# data = edgeList\n",
        "numMF = numMutualCoAuthors(data)\n",
        "numMF.takeSample(False,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwyUx6FfNEPA"
      },
      "source": [
        "The format of the output RDD should be of the following format:\n",
        "````{verbatim}\n",
        "[('33109-40583', 1),\n",
        " ('75663-261743', 1),\n",
        " ('83029-266423', 1),\n",
        " ('348648-379269', 3),\n",
        " ('36973-38262', 1),\n",
        " ('158280-190810', 2),\n",
        " ('97465-109654', 1),\n",
        " ('40020-86638', 1),\n",
        " ('49728-267552', 1),\n",
        " ('147445-208076', 1)]\n",
        "````"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}